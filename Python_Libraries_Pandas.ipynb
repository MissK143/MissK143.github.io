{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MissK143/MissK143.github.io/blob/main/Python_Libraries_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Pandas\n",
        "\n",
        "## Welcome to Pandas\n",
        "\n",
        "Pandas is a powerful Python library for data analysis and manipulation. It's built on top of the NumPy library and provides easy-to-use data structures and data analysis tools. This chapter will introduce you to the basics of Pandas, making it perfect for beginners. Let's dive in!\n",
        "\n",
        "### What is Pandas?\n",
        "\n",
        "Pandas is an open-source library that provides high-performance, easy-to-use data structures and data analysis tools. It's particularly suited for working with structured data (similar to SQL tables or Excel spreadsheets) where we want to perform complex data manipulations and analysis easily.\n",
        "\n",
        "### Why Use Pandas?\n",
        "\n",
        "- **Data manipulation**: Easily transform and manipulate large datasets.\n",
        "- **Data analysis**: Perform complex data analysis tasks with simple commands.\n",
        "- **Data cleaning**: Quickly clean messy datasets, filling missing values, or dropping rows or columns.\n",
        "- **Data visualization**: Although Pandas is not primarily a data visualization library, it seamlessly integrates with Matplotlib for basic plotting.\n",
        "\n",
        "### Installation and Setup\n",
        "\n",
        "Pandas is included in the standard Anaconda installation. However, if you need to install Pandas separately, you can do so using pip. Run the following command in your Jupyter notebook:\n",
        "\n"
      ],
      "metadata": {
        "id": "e6XX7QckQ9Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "EudsQ-4KQ9wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Pandas\n",
        "\n",
        "To start using Pandas, we first need to import it into our Jupyter notebook. It's conventional to import Pandas with the alias `pd`:\n"
      ],
      "metadata": {
        "id": "DBdoaNGmRLU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "QmDm5gHrRJBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, we'll import NumPy since it's often used alongside Pandas for numerical computations:"
      ],
      "metadata": {
        "id": "hYQ9ntF0ROWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "hN_BIX1kRMh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2: Data Structures in Pandas\n",
        "\n",
        "Pandas is built on two fundamental data structures: Series and DataFrame. Understanding these structures is key to mastering data manipulation and analysis with Pandas. In this chapter, we'll explore both Series and DataFrames in detail, covering creation, operations, and practical examples.\n",
        "\n",
        "## Series\n",
        "\n",
        "A Series is a one-dimensional array-like object containing a sequence of values (similar to a Python list) and an associated array of data labels, called its index. The simplest Series is formed from only an array of data.\n",
        "\n",
        "### Creating Series\n",
        "\n",
        "A Series can be created in several ways, including from lists, numpy arrays, and dictionaries.\n"
      ],
      "metadata": {
        "id": "lv1FglWAUeP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From a list\n",
        "ser1 = pd.Series([1, 2, 3, 4])\n",
        "print(ser1)"
      ],
      "metadata": {
        "id": "qiAvu2l8UekV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From a numpy array\n",
        "arr = np.array([1, 2, 3, 4])\n",
        "ser2 = pd.Series(arr)\n",
        "print(ser2)"
      ],
      "metadata": {
        "id": "xBMR4KGgUiSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From a dictionary\n",
        "dict = {'a': 1, 'b': 2, 'c': 3}\n",
        "ser3 = pd.Series(dict)\n",
        "print(ser3)\n"
      ],
      "metadata": {
        "id": "rNRKZjMWUquF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing and Selecting Data\n",
        "\n",
        "You can access individual elements of a Series through indexing similar to numpy arrays.\n"
      ],
      "metadata": {
        "id": "DmgxGANsU4V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing the first element\n",
        "print(ser1[0])"
      ],
      "metadata": {
        "id": "Q4wIfnACUsGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing elements by custom index when created from a dictionary\n",
        "print(ser3['a'])\n"
      ],
      "metadata": {
        "id": "hiLFdFVsU7-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Operations with Series\n",
        "\n",
        "Series supports many operations, which can be broadly classified into arithmetic operations, aggregation operations, and boolean operations.\n"
      ],
      "metadata": {
        "id": "0vW0wKuzU_4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Arithmetic operations\n",
        "ser = pd.Series([1, 2, 3, 4])\n",
        "print(ser + 10)\n"
      ],
      "metadata": {
        "id": "KG51e90DU8Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregation operations\n",
        "print(ser.sum())\n",
        "print(ser.mean())\n"
      ],
      "metadata": {
        "id": "B198XBzxVCZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boolean operations\n",
        "print(ser > 2)\n"
      ],
      "metadata": {
        "id": "eFM4OR1yVEsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataFrame\n",
        "\n",
        "A DataFrame is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns). It is the most commonly used pandas object for data analysis.\n",
        "\n",
        "### Creating DataFrames\n",
        "\n",
        "DataFrames can be created from various data structures like lists, dictionaries, Series, and even numpy arrays.\n"
      ],
      "metadata": {
        "id": "Y1ortpwuVPKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From a dictionary of series\n",
        "df1 = pd.DataFrame({'A': ser1, 'B': ser2})\n",
        "df1"
      ],
      "metadata": {
        "id": "2DWVenx3VF7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From a list of dictionaries\n",
        "lst_of_dicts = [{'a': 1, 'b': 2}, {'a': 5, 'b': 10, 'c': 20}]\n",
        "df2 = pd.DataFrame(lst_of_dicts)\n",
        "df2"
      ],
      "metadata": {
        "id": "zdRSUOjyVQ3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From a numpy array\n",
        "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "df3 = pd.DataFrame(numpy_array, columns=['A', 'B', 'C'])\n",
        "df3"
      ],
      "metadata": {
        "id": "8WFP7JFlVULl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Selection and Indexing\n",
        "\n",
        "Selecting and indexing in DataFrames allows you to retrieve individual data or subsets of your data.\n"
      ],
      "metadata": {
        "id": "IaxK0NmkVgSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "OlOU9oyy3Z2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting a single column\n",
        "df1['A']"
      ],
      "metadata": {
        "id": "R-ClQ4jnVc60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting multiple columns\n",
        "df1[['A', 'B']]\n"
      ],
      "metadata": {
        "id": "2X8vTgWrVh52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataFrame Operations\n",
        "\n",
        "DataFrames support a wide range of operations, from arithmetic operations to complex aggregations and transformations.\n"
      ],
      "metadata": {
        "id": "cY4cjGNMVnEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Arithmetic operations\n",
        "df1 + 10\n"
      ],
      "metadata": {
        "id": "5tA730jOVlkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregation\n",
        "df1.mean()"
      ],
      "metadata": {
        "id": "u8l6SeQ8VonV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying functions\n",
        "df1.apply(np.sqrt)"
      ],
      "metadata": {
        "id": "wVU02cfgVp72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison between Series and DataFrame\n",
        "\n",
        "- **Dimensionality**: Series is one-dimensional, while DataFrame is two-dimensional.\n",
        "- **Data structure**: Series can be considered as a single column of data, while DataFrame is more like a collection of Series objects put together to form a table.\n",
        "- **Use case**: Use Series when you need a single array of data with an index, and use DataFrame when you need to represent and manipulate tabular data with rows and columns.\n"
      ],
      "metadata": {
        "id": "KzwEc5cUWAze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3: Basic Operations with DataFrames\n",
        "\n",
        "DataFrames are central to data manipulation and analysis in Pandas. This chapter dives deep into the various operations you can perform with DataFrames, starting from viewing and selecting data, to adding and dropping rows or columns, and much more. Understanding these operations is crucial for any data analysis task.\n",
        "\n",
        "## Viewing Data\n",
        "\n",
        "One of the first steps in data analysis is to understand the structure and content of your dataset. Pandas provides several methods to get a quick overview of your DataFrame.\n",
        "\n",
        "### Head and Tail\n",
        "\n",
        "- `head(n)`: This method returns the first `n` rows of the DataFrame. By default, `n=5`.\n",
        "- `tail(n)`: Similarly, `tail(n)` returns the last `n` rows.\n"
      ],
      "metadata": {
        "id": "72pBDv9MWHhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample DataFrame\n",
        "df = pd.DataFrame({'A': range(1, 11), 'B': range(11, 21)})\n"
      ],
      "metadata": {
        "id": "uBlJGnhLV0Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the first 3 rows\n",
        "df.head(3)\n"
      ],
      "metadata": {
        "id": "c-zKWR6xWQ4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the last 3 rows\n",
        "print(df.tail(3))\n"
      ],
      "metadata": {
        "id": "9GiwefvrWRwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Descriptive Statistics\n",
        "\n",
        "- `describe()`: This method provides a quick overview of the statistical distribution of numerical columns â€“ count, mean, std (standard deviation), min, quartiles, and max.\n"
      ],
      "metadata": {
        "id": "uf2lvQLIWUQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive statistics\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "id": "OxdUSDq0WSu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sw6QuGymWXRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Info\n",
        "\n",
        "- `info()`: Provides a concise summary of the DataFrame, including the number of non-null entries in each column, the data type of each column, and the memory usage.\n"
      ],
      "metadata": {
        "id": "2uiV0m36WXU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "OQib6CbRWV2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Selection\n",
        "\n",
        "Selecting specific subsets of data is a common task in data analysis. Pandas provides multiple ways to select and index rows and columns in DataFrames.\n",
        "\n",
        "### Column Selection\n",
        "\n",
        "You can select a column using its label, returning a Series, or pass a list of labels to select multiple columns, returning a DataFrame.\n"
      ],
      "metadata": {
        "id": "UM0TGfIjWcS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting a single column\n",
        "series_a = df['A']\n",
        "print(series_a)\n"
      ],
      "metadata": {
        "id": "M-rWXE62WY-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting multiple columns\n",
        "df_subset = df[['A', 'B']]\n",
        "print(df_subset)"
      ],
      "metadata": {
        "id": "JerEtVahWet2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Row Selection\n",
        "\n",
        "Rows can be selected by position using `iloc` or by label using `loc`.\n",
        "\n",
        "- `iloc`: Integer-location based indexing for selection by position.\n",
        "- `loc`: Label-location based indexer for selection by label.\n"
      ],
      "metadata": {
        "id": "nd8FhP9zWqpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting a single row by position\n",
        "row_by_position = df.iloc[0]\n",
        "print(row_by_position)"
      ],
      "metadata": {
        "id": "l9g5-Px5Wpz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting a row by label\n",
        "# Note: If your index is integer-based, this will look similar to iloc, but it's label-based.\n",
        "row_by_label = df.loc[0]\n",
        "print(row_by_label)"
      ],
      "metadata": {
        "id": "P0YMjuTnWub1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Slicing\n",
        "\n",
        "Pandas supports slicing rows or columns using `iloc` and `loc`.\n"
      ],
      "metadata": {
        "id": "U1qSE3YuW8mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing rows\n",
        "rows_slice = df.iloc[1:4]\n",
        "print(rows_slice)"
      ],
      "metadata": {
        "id": "6p42fUw8Wyo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing columns\n",
        "# Note: For `iloc`, columns are also indexed by their integer positions.\n",
        "columns_slice = df.iloc[:, 0:2]\n",
        "print(columns_slice)"
      ],
      "metadata": {
        "id": "RmL7JiUEW_1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding and Dropping Columns\n",
        "\n",
        "### Adding Columns\n",
        "\n",
        "You can add a new column to a DataFrame simply by assigning it to the DataFrame with a new column label.\n"
      ],
      "metadata": {
        "id": "TxBcNwMJXelO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a new column\n",
        "df['C'] = range(21, 31)\n"
      ],
      "metadata": {
        "id": "OnrRIasIXD9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropping Columns\n",
        "\n",
        "Columns can be removed using the `drop` method, specifying the `axis=1` for columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "uoqvWa4EXh7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping a column\n",
        "df_dropped = df.drop('C', axis=1)\n"
      ],
      "metadata": {
        "id": "zv2abwooXgBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conditional Selection\n",
        "\n",
        "Pandas allows for conditional selection using column values.\n",
        "\n"
      ],
      "metadata": {
        "id": "fM25ZmEYXk-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conditional selection\n",
        "condition = df['A'] > 5\n",
        "print(condition)"
      ],
      "metadata": {
        "id": "Fsx0CeplXjsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df[condition]\n",
        "print(filtered_df)"
      ],
      "metadata": {
        "id": "BQgW85G5XmhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting and Resetting Index\n",
        "\n",
        "### Setting Index\n",
        "\n",
        "You can set one of the columns as an index using `set_index`.\n"
      ],
      "metadata": {
        "id": "_q38Wt67X3P-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting 'A' as the index\n",
        "df_with_new_index = df.set_index('A')\n",
        "df_with_new_index"
      ],
      "metadata": {
        "id": "5QeVZVTAXx2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resetting Index\n",
        "\n",
        "To revert to the default integer index, use `reset_index`.\n"
      ],
      "metadata": {
        "id": "7x1dNkqgX9be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resetting index\n",
        "df_reset = df_with_new_index.reset_index()\n",
        "df_reset"
      ],
      "metadata": {
        "id": "_SfXVWOcX40l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4: Data Manipulation and Cleaning with Pandas\n",
        "\n",
        "In this chapter, we explore the intricate world of data manipulation and cleaning using Pandas, a cornerstone in the daily workflow of data scientists and analysts. The integrity and usability of data directly influence the outcomes of analyses and models. As such, Pandas provides a robust toolkit for addressing common data issues, including handling missing data, cleaning datasets, transforming data types, and applying functions to enrich and prepare data for analysis.\n",
        "\n",
        "### Handling Missing Data\n",
        "Missing data is a common occurrence in datasets and needs to be addressed to prevent skewed analyses and inaccurate results. Pandas offers several methods for detecting, removing, and imputing missing values in DataFrames and Series.\n",
        "\n",
        "#### Detecting Null Values\n",
        "\n",
        "The first step in handling missing data is detecting its presence. Pandas provides two methods for this: `.isnull()` and `.notnull()`. Both return a boolean mask over the data indicating the presence or absence of missing data.\n"
      ],
      "metadata": {
        "id": "TQKZ22z3Z3uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with missing values\n",
        "df = pd.DataFrame({'Name': ['Alice', 'Bob', np.nan], 'Age': [24, np.nan, 30], 'Salary': [50000, 60000, 45000]})\n",
        "\n",
        "# Detect missing values\n",
        "print(df.isnull())\n"
      ],
      "metadata": {
        "id": "fkuFdqrkX-x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dropping Null Values\n",
        "\n",
        "Pandas `.dropna()` method allows you to exclude axes with missing data. The method can be fine-tuned with parameters to target specific rows or columns and how to handle partially missing data.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sNEI9FTvagLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any rows with missing values\n",
        "df_dropna_rows = df.dropna()\n",
        "print(df_dropna_rows)"
      ],
      "metadata": {
        "id": "Bxb2aqcWacqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns with any missing values\n",
        "df_dropna_cols = df.dropna(axis=1)\n",
        "print(df_dropna_cols)"
      ],
      "metadata": {
        "id": "eZ7XNbaDalPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where all cells are missing\n",
        "df_dropna_all = df.dropna(how='all')\n",
        "print(df_dropna_all)"
      ],
      "metadata": {
        "id": "B-iHFhBdaowk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Filling Null Values\n",
        "\n",
        "Rather than removing missing data, another approach is to impute missing values using the `.fillna()` method. This can be a specific value, a computed value (e.g., mean, median), or a method like forward-fill or back-fill.\n"
      ],
      "metadata": {
        "id": "J1fQOHnGawLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with a specific value\n",
        "df_filled = df.fillna(value=0)\n",
        "print(df_filled)"
      ],
      "metadata": {
        "id": "1O5p-ieZargG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with the mean of the column\n",
        "df_fill_mean = df['Age'].fillna(value=df['Age'].mean())\n",
        "print(df_fill_mean)"
      ],
      "metadata": {
        "id": "e4Fd-DxZayfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward-fill to propagate the last valid observation forward\n",
        "df_ffill = df.fillna(method='ffill')\n",
        "print(df_ffill)"
      ],
      "metadata": {
        "id": "pAkQ3ivda-TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Back-fill to propagate the next valid observation backward\n",
        "df_bfill = df.fillna(method='bfill')\n",
        "print(df_bfill)"
      ],
      "metadata": {
        "id": "ZQbjJmS3bANW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type Conversion\n",
        "\n",
        "Ensuring data is of the correct type is crucial for analyses and computations. Pandas allows for explicit type conversion using the `.astype()` method, catering to the need for numerical computations, string manipulations, or categorical data handling.\n"
      ],
      "metadata": {
        "id": "3akg_cabbEmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert column to string\n",
        "df['Salary'] = df['Salary'].astype(str)\n",
        "df"
      ],
      "metadata": {
        "id": "SLnz84lUbCwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Salary'] = df['Salary'].astype(int)"
      ],
      "metadata": {
        "id": "ZdxkGPdbcN9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert column to category\n",
        "df['Name'] = df['Name'].astype('category')\n",
        "df"
      ],
      "metadata": {
        "id": "xgNOBAIrbIIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Renaming Columns\n",
        "\n",
        "Renaming columns in Pandas is straightforward using the `.rename()` method, which supports a variety of inputs for specifying new column names, enhancing readability and convenience in data handling.\n"
      ],
      "metadata": {
        "id": "1X1klQCcbo6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns using a dictionary\n",
        "df_renamed = df.rename(columns={'Age': 'Employee Age', 'Salary': 'Employee Salary'})\n",
        "print(df_renamed)"
      ],
      "metadata": {
        "id": "DLtwvuHDbO1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns in-place\n",
        "df.rename(columns={'Name': 'Employee Name'}, inplace=True)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "X-zsfUZAbrXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sorting Data\n",
        "\n",
        "Sorting data can aid in understanding datasets, identifying patterns, or preparing for analysis. Pandas `.sort_values()` method offers extensive functionality for sorting data by one or more columns, in ascending or descending order.\n"
      ],
      "metadata": {
        "id": "y_pRxL-sbvym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by 'Age' in ascending order\n",
        "df_sorted_age = df.sort_values(by='Age')\n",
        "df_sorted_age"
      ],
      "metadata": {
        "id": "JTM5PsCmbtqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering Data\n",
        "\n",
        "Filtering is selecting subsets of data based on criteria. This is commonly performed using boolean indexing in Pandas, which involves passing a boolean array to the DataFrame to filter rows.\n"
      ],
      "metadata": {
        "id": "eCO36vGeb6Je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where Age is greater than 30\n",
        "df_filtered = df[df['Age'] > 25]\n",
        "df_filtered"
      ],
      "metadata": {
        "id": "cFwpI_O_b0Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Understanding Functions in Pandas\n",
        "- Overview of functions in pandas: built-in functions, user-defined functions, and lambda functions.\n",
        "- Difference between element-wise functions and aggregation functions.\n",
        "\n",
        "#### Applying Functions to Series and DataFrame\n",
        "- `apply()`: Applying a function along an axis of the DataFrame or on values of Series.\n",
        "- `applymap()`: Applying a function element-wise on a DataFrame.\n",
        "- `map()`: Applying a function element-wise on a Series.\n",
        "- `agg()`: Using aggregation functions on DataFrame/Series.\n"
      ],
      "metadata": {
        "id": "G4meXiwgcIYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ngVRM9MHdVhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a simple function to double the value\n",
        "def double_value(x):\n",
        "    return x * 2\n",
        "\n",
        "# Applying function to a column\n",
        "df['doubled_column'] = df['Age'].apply(double_value)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "C9pwudv2cETm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to Lambda Functions\n",
        "\n",
        "Lambda functions in Python are small anonymous functions defined with the lambda keyword. They can take any number of arguments but can only have one expression. When working with data manipulation libraries like pandas, lambda functions become extremely useful for applying quick and concise operations over DataFrame columns or rows without needing to define traditional function definitions.\n",
        "\n",
        "A lambda function's syntax is:\n",
        "```python\n",
        "lambda arguments: expression\n",
        "```\n",
        "The `expression` is executed and the result is returned.\n",
        "\n",
        "### Why Use Lambda Functions in Pandas?\n",
        "\n",
        "- **Conciseness**: They make your code more concise and readable, especially for simple operations.\n",
        "- **No Defining Functions**: They eliminate the need for defining a standard function for short, one-off operations.\n",
        "- **Flexibility**: They are highly flexible and can be used in a variety of situations with pandas objects.\n"
      ],
      "metadata": {
        "id": "Igd6loSffgq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
        "    'Age': [28, 34, 29, 40],\n",
        "    'Salary': [50000, 62000, 58000, 75000]\n",
        "}\n",
        "\n",
        "# Creating DataFrame\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "Q7UmyHBrfiUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose you want to categorize employees based on their salary:"
      ],
      "metadata": {
        "id": "qyn2CyO_fsix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Salary_Category'] = df['Salary'].apply(lambda x: 'High' if x > 60000 else 'Medium' if x > 55000 else 'Low')\n",
        "df"
      ],
      "metadata": {
        "id": "-DtoDPuDfonN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `map()` function is often used to transform data in a Series. With a lambda function, this becomes very powerful:"
      ],
      "metadata": {
        "id": "2WdgsWiIgBY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Age_Group'] = df['Age'].map(lambda x: '30s' if x >= 30 else '20s')\n",
        "df"
      ],
      "metadata": {
        "id": "i9Lhixcjf5pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use a lambda function with `apply()` across rows by specifying `axis=1`. This is useful for operations that need values from multiple columns:"
      ],
      "metadata": {
        "id": "o_n2iZODgZup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Custom_Calculation'] = df.apply(lambda row: row['Salary'] / row['Age'], axis=1)\n",
        "df"
      ],
      "metadata": {
        "id": "PPhnJ1h_gDYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5: Advanced DataFrame Operations\n",
        "\n",
        "### Grouping and Aggregating Data\n",
        "\n",
        "#### GroupBy Mechanics\n",
        "\n",
        "GroupBy operations are pivotal for summarizing datasets, enabling you to perform calculations over subsets of data. This process involves one or more of the following steps:\n",
        "- Splitting the data into groups based on some criteria.\n",
        "- Applying a function to each group independently.\n",
        "- Combining the results into a data structure.\n"
      ],
      "metadata": {
        "id": "MqEYsp0Eg6z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Category': ['A', 'B', 'A', 'B', 'C', 'A', 'B', 'C'],\n",
        "    'Values': [10, 20, 15, 25, 5, 15, 20, 10]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "id": "15eAqv_AhBL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping by 'Category' and calculating the sum of 'Values'\n",
        "grouped = df.groupby('Category').sum()\n",
        "print(grouped)"
      ],
      "metadata": {
        "id": "Ca0OhVREhEHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aggregate Functions\n",
        "\n",
        "Pandas provides several built-in methods for aggregating data, like `sum()`, `mean()`, `max()`, and `min()`. You can apply multiple aggregation functions at once by using the `.agg()` method.\n"
      ],
      "metadata": {
        "id": "Tn-V7UrrhLoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using agg() to apply multiple aggregation functions\n",
        "agg_functions = df.groupby('Category').agg({'Values': ['mean', 'min', 'max']})\n",
        "\n",
        "print(agg_functions)\n"
      ],
      "metadata": {
        "id": "FK2XjCmZhIPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pivot Tables and Cross-tabulations\n",
        "\n",
        "Pivot tables are a technique in data processing that allows you to summarize data in a structured format. Cross-tabulation, on the other hand, is a method to quantitatively analyze the relationship between multiple variables.\n",
        "\n",
        "#### Pivot Tables\n"
      ],
      "metadata": {
        "id": "dm9UoYqvhS5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a pivot table\n",
        "pivot_table = df.pivot_table(values='Values', index='Category', aggfunc='mean')\n",
        "\n",
        "print(pivot_table)\n"
      ],
      "metadata": {
        "id": "W0dvvGi7hNwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross-tabulations"
      ],
      "metadata": {
        "id": "GzHqg_IFha9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-tabulation of two factors\n",
        "cross_tab = pd.crosstab(df['Category'], df['Values'])\n",
        "\n",
        "print(cross_tab)\n"
      ],
      "metadata": {
        "id": "IpN_5FEBhU4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merging, Joining, and Concatenating DataFrames\n",
        "\n",
        "Combining datasets is a common operation in data manipulation, and Pandas offers several functions to accomplish this, such as `merge()`, `join()`, and `concat()`.\n",
        "\n",
        "#### Merging DataFrames\n"
      ],
      "metadata": {
        "id": "IkPnjU8Thj83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame({'Key': ['K0', 'K1', 'K2', 'K3'],\n",
        "                    'A': ['A0', 'A1', 'A2', 'A3'],\n",
        "                    'B': ['B0', 'B1', 'B2', 'B3']})\n",
        "\n",
        "df2 = pd.DataFrame({'Key': ['K0', 'K1', 'K2', 'K3'],\n",
        "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
        "                    'D': ['D0', 'D1', 'D2', 'D3']})\n"
      ],
      "metadata": {
        "id": "WQ8EreeMhdHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "8rSVYyiahnFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "S9lSKYwghp81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging df1 and df2 on 'Key'\n",
        "merged_df = pd.merge(df1, df2, on='Key')\n",
        "\n",
        "print(merged_df)"
      ],
      "metadata": {
        "id": "0TYOwGt3hqS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Joining DataFrames"
      ],
      "metadata": {
        "id": "h54Ys0clhvqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining DataFrames on index\n",
        "joined_df = df1.join(df2.set_index('Key'), on='Key')\n",
        "\n",
        "print(joined_df)\n"
      ],
      "metadata": {
        "id": "Cedz-GTvhsD0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}